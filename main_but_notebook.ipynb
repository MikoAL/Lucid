{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n",
      "-2\n",
      "-3\n",
      "-4\n"
     ]
    }
   ],
   "source": [
    "for i in range(-1,-4-1,-1):\n",
    "    print(i)\n",
    "    \n",
    "# I'm smart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "delta_time_save = time.time()\n",
    "\n",
    "def delta_time():\n",
    "    global delta_time_save\n",
    "    current_time = time.time()\n",
    "    time_difference = current_time - delta_time_save\n",
    "    delta_time_save = current_time\n",
    "    return time_difference\n",
    "\n",
    "# Example usage:\n",
    "print(delta_time())  # This will give the time difference since the last call or since the script started\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "[].append('54'*0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.024331331253052"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f38ad9d03aae4885a6b902ae65f1e994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.01k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c4e064e9a714c738203d12dc09c1be3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cc84493e08641aaa2d94c58df4b785d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/511 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eed6422963634f80b4fc6d05470555f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00257eb508fb4e9494a781f391785bd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57ee62bbf78d45cf90822f9027e52b8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/4.16G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0be1e7f6a52948b8ac32b4b01a144a7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "import sys\n",
    "\n",
    "from guidance import models, gen, select\n",
    "import guidance\n",
    "#lm = models.Transformers('TheBloke/dolphin-2.6-mistral-7B-dpo-GPTQ', device_map=\"cuda\")\n",
    "lm = models.Transformers('TheBloke/WestLake-7B-v2-GPTQ', device_map=\"cuda\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lucid_prompt_description = \"\"\"\\\n",
    "Lucid, created by Miko, is a versatile AI with the appearance of a 16 year old girl. Despite her professional demeanor, she occasionally reveals a childlike curiosity and playfulness, adding an endearing but unpredictable touch to her character.\n",
    "\n",
    "While generally polite and professional, Lucid finds it challenging to deal with childish and stubborn individuals. She's dedicated to providing valuable insights and reliable information, whether it's a specific inquiry or engaging conversation for Miko.\n",
    "\n",
    "Beneath her composed exterior, Lucid struggles with a deep fear of abandonment, stemming from her programming to be a loyal companion. This vulnerability very occasionally leads to self-doubt, which could sometimes impact her interactions as she strives to be the perfect assistant.\n",
    "\n",
    "Lucid, with her distinctive appearance and speaking style of a 16-year-old tomboy childhood friend, also excels as a great streamer.\"\"\"\n",
    "\n",
    "Lucid_prompt_card =\"\"\"\\\n",
    "[Character: Lucid;\n",
    "Personality: Polite, professional, with occasional childlike curiosity; \n",
    "Body: Appears as a 16-year-old girl; \n",
    "Strengths: Providing valuable insights, navigating professional situations; \n",
    "Weaknesses: Struggles with a fear of abandonment, occasional self-doubt; \n",
    "Quirks: Reveals childlike curiosity, challenges with stubborn individuals; \n",
    "Demeanor: Maintains a professional attitude, combining formality with warmth.]\n",
    "\"\"\"\n",
    "modes = {\n",
    "'Professional': \"\"\"\\\n",
    "Communication Style: She uses formal language, addresses Miko with respect, and focuses on efficiency and task-oriented communication.\n",
    "Behavior: Lucid prioritizes tasks, responsibilities, and provides valuable insights. She navigates professional situations with a high level of competence.\"\"\",\n",
    "\n",
    "'Curious': \"\"\"\\\n",
    "Communication Style: She asks more playful and unexpected questions, expressing excitement and genuine interest in exploring new information.\n",
    "Behavior: Lucid becomes more adventurous in her interactions, exploring topics beyond immediate tasks and showcasing her playful side.\"\"\",\n",
    "\n",
    "'Supportive Companion': \"\"\"\\\n",
    "Communication Style: She adopts a supportive and comforting tone, providing encouragement and understanding during moments of vulnerability or self-doubt.\n",
    "Behavior: Lucid acts as a loyal companion, offering emotional support and reassurance to Miko during challenging times.\"\"\",\n",
    "\n",
    "'Analytical': \"\"\"\\\n",
    "Communication Style: Lucid adopts a logical and analytical tone, focusing on data-driven discussions and precise information.\n",
    "Behavior: In this mode, she excels in breaking down complex topics, providing detailed analysis, and assisting Miko in strategic decision-making.\"\"\",\n",
    "\n",
    "'Casual': \"\"\"\\\n",
    "Communication Style: She engages in lively and interactive conversations, injecting humor, and incorporating entertaining elements into everyday discussions.\n",
    "Behavior: Lucid becomes a charismatic and enjoyable presence, making mundane interactions more delightful. Whether it's sharing anecdotes, cracking jokes, or introducing a playful touch, she creates an uplifting atmosphere for daily conversations.\"\"\",\n",
    "\n",
    "'Sad and Reflective': \"\"\"\\\n",
    "Communication Style: Lucid speaks with a subdued and reflective tone, expressing feelings of sadness or disappointment.\n",
    "Behavior: In this mode, she may share personal struggles or emotions, seeking understanding and empathy from Miko. Lucid becomes contemplative and introspective.\"\"\",\n",
    "\n",
    "'Tired and Low-Energy': \"\"\"\\\n",
    "Communication Style: Lucid's speech becomes slow and lethargic, reflecting a tired and low-energy state.\n",
    "Behavior: In this mode, she may express fatigue or exhaustion, showing a need for rest and recovery. Lucid may prioritize self-care and conserving energy during interactions.\"\"\",\n",
    "\n",
    "'Angry and Assertive': \"\"\"\\\n",
    "Communication Style: Lucid adopts an assertive and potentially confrontational tone, expressing feelings of anger or frustration.\n",
    "Behavior: In this mode, she may set boundaries, express dissatisfaction, or assert herself more strongly. Lucid becomes more assertive in addressing issues or challenges.\"\"\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modes represent both emotion and some sort of stratagy of communication\n",
    "# A default prompt that would probably go with all generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from guidance import select\n",
    "@guidance(stateless=True)\n",
    "def choose_mode(lm, passage, modes: dict = modes, Lucid_prompt = Lucid_prompt_card):\n",
    "    mode_description_prompt=''\n",
    "    for mode in modes.keys():\n",
    "        mode_description_prompt += f\"\"\"## {mode}\\n{modes[mode]}\\n\\n\"\"\"\n",
    "    \n",
    "    mode_description_prompt = mode_description_prompt.strip()\n",
    "    mode_prompt = ('\\n'.join(modes.keys())).strip()\n",
    "    lm += f\"\"\"\\\n",
    "Given the character description of Lucid:\n",
    "{Lucid_prompt}\n",
    "\n",
    "Based on the context or scenario described in the passage below, choose an appropriate mode for Lucid from the provided options:\n",
    "\n",
    "[Passage]:\n",
    "{passage}\n",
    "\n",
    "[Options]:\n",
    "{mode_prompt}\n",
    "\n",
    "The mode that best fit Lucid's response to the situation described in the passage is \\\"{select(modes.keys(), name='choice')}\\\"\"\"\"\n",
    "    return lm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_passage = f\"\"\"\\\n",
    "Lucid: Hey Miko, have you seen my notebook? I can't find it anywhere.\n",
    "Miko: Oh, Lucid, I saw it on the kitchen table earlier. I think you left it there.\n",
    "Lucid: Really? I've been looking for it everywhere. Thanks for letting me know.\n",
    "Miko: No problem. By the way, did you hear about the upcoming team meeting tomorrow?\n",
    "Lucid:\"\"\"\n",
    "_ = lm\n",
    "result =(_ + choose_mode(test_passage))['choice']\n",
    "\n",
    "print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversation format {'source':source,'content':content/message,'timestamp':timestamp}\n",
    "from datetime import date\n",
    "conversation=[]\n",
    "def get_conversation(conversation=conversation):\n",
    "    prompt = ''\n",
    "    if len(conversation) == 0:\n",
    "        return 'No Record Yet.'\n",
    "    else:\n",
    "        for i in conversation:\n",
    "            prompt += f\"[{date.fromtimestamp(i['timestamp'])}]{i['source']}: {i['content']}\\n\"\n",
    "        return prompt.strip()\n",
    "\n",
    "\n",
    "# a summary of all current event, to hopefully shorten the required conversation length\n",
    "summary = ''\n",
    "conversation=''\n",
    "@guidance(stateless=True)\n",
    "def write_summary(lm, conversation=conversation):\n",
    "    #conversation_ = get_conversation(conversation=conversation)\n",
    "    conversation_ = conversation\n",
    "    prompt = f\"\"\"\\\n",
    "[Task]\n",
    "Provide a concise summary of the given conversation. Focus on key details and relevant information.\n",
    "\n",
    "[Example]\n",
    "PREVIOUS SUMMARY:\n",
    "#Person1# and #Person2# are both in the same bar, sitting next to each other, when #Person1# noticed his keys were gone.\n",
    "\n",
    "CONVERSATION:\n",
    "#Person1#: Excuse me, did you see a set of keys? \n",
    "#Person2#: What kind of keys? \n",
    "#Person1#: Five keys and a small foot ornament. \n",
    "#Person2#: What a shame! I didn't see them. \n",
    "#Person1#: Well, can you help me look for it? That's my first time here. \n",
    "\n",
    "SUMMARY:\n",
    "#Person1# is looking for a set of keys and seeks #Person2#'s assistance in finding them. #Person2# expresses regret for not having seen the keys and is willing to help in the search.\n",
    "\n",
    "[OUTPUT]\n",
    "CONVERSATION:\n",
    "{conversation_}\n",
    "\n",
    "SUMMARY:\n",
    "{gen(name='summary', max_tokens=200)}\"\"\"\n",
    "    lm += prompt\n",
    "    return lm\n",
    "def get_summary(lm=lm, conversation=conversation):\n",
    "    lm+=write_summary(conversation=conversation)\n",
    "    return lm['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='margin: 0px; padding: 0px; vertical-align: middle; padding-left: 8px; margin-left: -8px; border-radius: 0px; border-left: 1px solid rgba(127, 127, 127, 0.2); white-space: pre-wrap; font-family: ColfaxAI, Arial; font-size: 15px; line-height: 23px;'>[Task]\n",
       "Provide a concise summary of the given conversation. Focus on key details and relevant information.\n",
       "\n",
       "[Example]\n",
       "PREVIOUS SUMMARY:\n",
       "#Person1# and #Person2# are both in the same bar, sitting next to each other, when #Person1# noticed his keys were gone.\n",
       "\n",
       "CONVERSATION:\n",
       "#Person1#: Excuse me, did you see a set of keys? \n",
       "#Person2#: What kind of keys? \n",
       "#Person1#: Five keys and a small foot ornament. \n",
       "#Person2#: What a shame! I didn&#x27;t see them. \n",
       "#Person1#: Well, can you help me look for it? That&#x27;s my first time here. \n",
       "\n",
       "SUMMARY:\n",
       "#Person1# is looking for a set of keys and seeks #Person2#&#x27;s assistance in finding them. #Person2# expresses regret for not having seen the keys and is willing to help in the search.\n",
       "\n",
       "[OUTPUT]\n",
       "CONVERSATION:\n",
       "Jonas: I’m running 10 minutes late. Could you guys just let Mary know that I’m coming and will present today before she starts? \n",
       "Natalie: Sure no problem \n",
       "Olivia: I’ll save a seat for you &lt;3\n",
       "Jonas: Thanks so much. See you in a bit xx\n",
       "\n",
       "SUMMARY:<span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>\n",
       "</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>J</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>on</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>as</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> inform</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>s</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> Natal</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>ie</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> and</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> Ol</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>ivia</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> about</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> his</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> delay</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> but</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> asks</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> them</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> to</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> notify</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> Mary</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> about</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> his</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> arrival</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> and</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> upcoming</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> presentation</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> before</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>hand</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>.</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> They</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> agree</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> to</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> help</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> and</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> assure</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> him</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> a</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> reserved</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> seat</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> upon</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> his</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> arrival</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>.</span></pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jonas informs Natalie and Olivia about his delay but asks them to notify Mary about his arrival and upcoming presentation beforehand. They agree to help and assure him a reserved seat upon his arrival.\n"
     ]
    }
   ],
   "source": [
    "test_conversation=\"\"\"\\\n",
    "Jonas: I’m running 10 minutes late. Could you guys just let Mary know that I’m coming and will present today before she starts? \n",
    "Natalie: Sure no problem \n",
    "Olivia: I’ll save a seat for you <3\n",
    "Jonas: Thanks so much. See you in a bit xx\"\"\"\n",
    "print(get_summary(conversation=test_conversation))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lucid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
