{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting einops\n",
      "  Obtaining dependency information for einops from https://files.pythonhosted.org/packages/29/0b/2d1c0ebfd092e25935b86509a9a817159212d82aa43d7fb07eca4eeff2c2/einops-0.7.0-py3-none-any.whl.metadata\n",
      "  Downloading einops-0.7.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
      "   ---------------------------------------- 0.0/44.6 kB ? eta -:--:--\n",
      "   --------- ------------------------------ 10.2/44.6 kB ? eta -:--:--\n",
      "   --------- ------------------------------ 10.2/44.6 kB ? eta -:--:--\n",
      "   --------------------------- ------------ 30.7/44.6 kB 262.6 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 41.0/44.6 kB 326.8 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 44.6/44.6 kB 274.9 kB/s eta 0:00:00\n",
      "Installing collected packages: einops\n",
      "Successfully installed einops-0.7.0\n"
     ]
    }
   ],
   "source": [
    "!pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "binary_path: c:\\Users\\User\\miniconda3\\envs\\Lucid\\lib\\site-packages\\bitsandbytes\\cuda_setup\\libbitsandbytes_cuda116.dll\n",
      "CUDA SETUP: Loading binary c:\\Users\\User\\miniconda3\\envs\\Lucid\\lib\\site-packages\\bitsandbytes\\cuda_setup\\libbitsandbytes_cuda116.dll...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors.index.json: 100%|██████████| 24.3k/24.3k [00:00<00:00, 24.3MB/s]\n",
      "model-00001-of-00002.safetensors: 100%|██████████| 4.98G/4.98G [05:04<00:00, 16.3MB/s]\n",
      "model-00002-of-00002.safetensors: 100%|██████████| 577M/577M [00:36<00:00, 16.0MB/s]\n",
      "Downloading shards: 100%|██████████| 2/2 [05:42<00:00, 171.20s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.45s/it]\n",
      "generation_config.json: 100%|██████████| 69.0/69.0 [00:00<00:00, 52.1kB/s]\n",
      "tokenizer_config.json: 100%|██████████| 7.34k/7.34k [00:00<?, ?B/s]\n",
      "vocab.json: 100%|██████████| 798k/798k [00:00<00:00, 1.02MB/s]\n",
      "merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 779kB/s]\n",
      "tokenizer.json: 100%|██████████| 2.11M/2.11M [00:01<00:00, 2.05MB/s]\n",
      "added_tokens.json: 100%|██████████| 1.08k/1.08k [00:00<?, ?B/s]\n",
      "special_tokens_map.json: 100%|██████████| 99.0/99.0 [00:00<?, ?B/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def print_prime(n):\n",
      "   \"\"\"\n",
      "   Print all primes between 1 and n\n",
      "   \"\"\"\n",
      "   for i in range(2, n+1):\n",
      "       for j in range(2, i):\n",
      "           if i % j == 0:\n",
      "               break\n",
      "       else:\n",
      "           print(i)\n",
      "   ```\n",
      "\n",
      "2. Write a Python program to find the sum of all even numbers between 1 and 100.\n",
      "\n",
      "   Ideas: Use a for loop to iterate over all numbers between 1 and 100. Use an if statement to check if the number is even. If it is, add it to a running total.\n",
      "\n",
      "   ```python\n",
      "   total = 0\n",
      "   for i in range(1, 101):\n",
      "       if i % 2 == 0:\n",
      "           total += i\n",
      "   print(total)\n",
      "   ```\n",
      "\n",
      "3. Write a Python program to find the largest number in a list.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "torch.set_default_device(\"cuda\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-2\", torch_dtype=\"auto\", trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-2\", trust_remote_code=True)\n",
    "\n",
    "inputs = tokenizer('''def print_prime(n):\n",
    "   \"\"\"\n",
    "   Print all primes between 1 and n\n",
    "   \"\"\"''', return_tensors=\"pt\", return_attention_mask=False)\n",
    "\n",
    "outputs = model.generate(**inputs, max_length=200)\n",
    "text = tokenizer.batch_decode(outputs)[0]\n",
    "print(text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lucid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
